version: '3.8'

services:
  
  indexer:
    profiles: [indexing]
    build:
      context: ../
      dockerfile: docker-compose-setup/Dockerfile
      args:
        CODE_ORIGIN: ${CODE_ORIGIN:-clone_github}
    depends_on:
      - weaviate
    network_mode: "service:weaviate"
    environment:
      SPARQL_ENDPOINT: ${ONTOLOGIES_SPARQL_ENDPOINT:? CONFIG PROBLEM - ONTOLOGIES_SPARQL_ENDPOINT is not set. Options to fix - 1) set in .env file 2) pass as environment variable e.g. ONTOLOGIES_SPARQL_ENDPOINT=... docker-compose up  or 3) additionally activate ontology auto-loading via embedded SPARQL endpoint (see README.md)} 
      WEAVIATE_PORT: ${WEAVIATE_PORT}
      WEAVIATE_PORT_GRPC: ${WEAVIATE_PORT_GRPC}
      DELETE_OLD_INDEX: ${DELETE_OLD_INDEX}
    command: >
      /bin/bash -c "source activate onto_search_env && sleep 20 && python VectorDB_creation.py"

  api:
    profiles: [serve-api]
    build:
      context: ../
      dockerfile: docker-compose-setup/Dockerfile
      args:
        CODE_ORIGIN: ${CODE_ORIGIN:-clone_github}
    network_mode: "service:weaviate"
    depends_on:
      - weaviate
    # ports:
    #   - "9091:9090"
    environment:
      WEAVIATE_PORT: ${WEAVIATE_PORT}
      WEAVIATE_PORT_GRPC: ${WEAVIATE_PORT_GRPC}
    command: >
      /bin/bash -c "source activate onto_search_env && sleep 20 && python API_main.py"
  
  # using text2vec TRANSFORMERS_INFERENCE_API base on docker container running hugingface transformers api endpoint
  weaviate:
    profiles: [indexing, serve-api]
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.27.0
    ports:
    - 8012:8080
    - 50053:50051
    volumes:
    - ./weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      TRANSFORMERS_INFERENCE_API: 'http://prebuilt-t2v-transformers-model:8080'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_API_BASED_MODULES: 'true'
      ENABLE_MODULES: 'text2vec-transformers'
      CLUSTER_HOSTNAME: 'node1'

  prebuilt-t2v-transformers-model:
    profiles: [indexing, serve-api]
    # for pre-built images from weaviate see https://cr.weaviate.io/v2/semitechnologies/transformers-inference/tags/list
    image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-mpnet-base-cos-v1-1.9.6
    environment:
      ENABLE_CUDA: '0'
      # OPENBLAS_NUM_THREADS: 8
    security_opt: # todo this needs to be refined
      - seccomp:unconfined